{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd875f7f-f87e-4503-b9b0-94f88079e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import megengine as mge\n",
    "import megengine.functional as F\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "from nets import Model\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994147f9-5ac4-40ab-bcd3-68e535db1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    print(\"Loading model:\", os.path.abspath(model_path))\n",
    "    pretrained_dict = mge.load(model_path)\n",
    "    model = Model(max_disp=256, mixed_precision=False, test_mode=True)\n",
    "    model.load_state_dict(pretrained_dict[\"state_dict\"], strict=True)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def inference(left, right, model, n_iter=20):\n",
    "    print(\"Model Forwarding...\")\n",
    "    imgL = left.transpose(2, 0, 1)\n",
    "    imgR = right.transpose(2, 0, 1)\n",
    "    imgL = np.ascontiguousarray(imgL[None, :, :, :])\n",
    "    imgR = np.ascontiguousarray(imgR[None, :, :, :])\n",
    "    imgL = mge.tensor(imgL).astype(\"float32\")\n",
    "    imgR = mge.tensor(imgR).astype(\"float32\")\n",
    "    imgL_dw2 = F.nn.interpolate(\n",
    "        imgL,\n",
    "        size=(imgL.shape[2] // 2, imgL.shape[3] // 2),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=True,\n",
    "    )\n",
    "    imgR_dw2 = F.nn.interpolate(\n",
    "        imgR,\n",
    "        size=(imgL.shape[2] // 2, imgL.shape[3] // 2),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=True,\n",
    "    )\n",
    "    pred_flow_dw2 = model(imgL_dw2, imgR_dw2, iters=n_iter, flow_init=None)\n",
    "    pred_flow = model(imgL, imgR, iters=n_iter, flow_init=pred_flow_dw2)\n",
    "    pred_disp = F.squeeze(pred_flow[:, 0, :, :]).numpy()\n",
    "    return pred_disp\n",
    "\n",
    "#loading the model\n",
    "model_func = load_model(\"crestereo_eth3d.mge\")\n",
    "\n",
    "#loading the rectification parametrs\n",
    "cv_file = cv2.FileStorage()\n",
    "cv_file.open('../stereoMap.xml', cv2.FileStorage_READ)\n",
    "stereoMapL_x = cv_file.getNode('stereoMapL_x').mat()\n",
    "stereoMapL_y = cv_file.getNode('stereoMapL_y').mat()\n",
    "stereoMapR_x = cv_file.getNode('stereoMapR_x').mat()\n",
    "stereoMapR_y = cv_file.getNode('stereoMapR_y').mat()\n",
    "\n",
    "#creating an avi file for the output\n",
    "out = cv2.VideoWriter('disp_body_test.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, (1280, 720))\n",
    "\n",
    "#loading the left and right videos\n",
    "vidcap_left = cv2.VideoCapture('../body_test_left.mp4')\n",
    "vidcap_right = cv2.VideoCapture('../body_test_right.mp4')\n",
    "success_left,left = vidcap_left.read()\n",
    "success_right,right = vidcap_right.read()\n",
    "count = 0\n",
    "\n",
    "while success_left and success_right:\n",
    "    \n",
    "    left = cv2.remap(left, stereoMapL_x, stereoMapL_y, cv2.INTER_LINEAR)\n",
    "    right= cv2.remap(right, stereoMapR_x, stereoMapR_y, cv2.INTER_LINEAR)\n",
    "    \n",
    "    in_h, in_w = left.shape[:2]\n",
    "    eval_h, eval_w = [int(e) for e in (1024,1536)]\n",
    "    left_img = cv2.resize(left, (eval_w, eval_h), interpolation=cv2.INTER_LINEAR)\n",
    "    right_img = cv2.resize(right, (eval_w, eval_h), interpolation=cv2.INTER_LINEAR)\n",
    "    pred = inference(left_img, right_img, model_func, n_iter=20)\n",
    "    t = float(in_w) / float(eval_w)\n",
    "    disp = cv2.resize(pred, (in_w, in_h), interpolation=cv2.INTER_LINEAR) * t\n",
    "    disp_vis = (disp - disp.min()) / (disp.max() - disp.min()) * 255.0\n",
    "    disp_vis = disp_vis.astype(\"uint8\")\n",
    "    disp_vis = cv2.applyColorMap(disp_vis, cv2.COLORMAP_INFERNO)\n",
    "    out.write(disp_vis)\n",
    "    success_left,left = vidcap_left.read()\n",
    "    success_right,right = vidcap_right.read()\n",
    "    count += 1\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30adfe-91fc-46ae-9cc1-0338555fb65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee4685-4033-4906-9e33-3be3fcf7ef1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a64e9c-4f6d-4d53-9d51-b2b605ef0aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fa2a250-da86-47e5-9fb7-686493b9eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = cv2.VideoWriter('Rotated_face_test_left.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, (720, 1280))\n",
    "# vidcap= cv2.VideoCapture('../face_test_left.mp4')\n",
    "# success,img = vidcap.read()\n",
    "# while success:\n",
    "#     rotated=cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "#     out.write(rotated)\n",
    "#     success,img = vidcap.read()\n",
    "# out.release()\n",
    "\n",
    "# from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "# ffmpeg_extract_subclip(\"Rotated_face_test_left.avi\", 6, 32, targetname=\"Rotated_face_test_left.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
